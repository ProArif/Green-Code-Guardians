##### chatgpt generation ######
chatgpt_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-chatgpt-formated.json"))
chatgpt_df <- as.data.frame(chatgpt_data)
unlist_chatgpt_pwu <- unlist(chatgpt_df$power.usage, use.names=FALSE)
filtered_chatgpt_pwu <- remove_outliers(unlist_chatgpt_pwu)
##### llama generation ######
llama_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-llama-formated.json"))
llama_df <- as.data.frame(llama_data)
unlist_llama_pwu <- unlist(llama_df$power.usage, use.names=FALSE)
filtered_llama_pwu <- remove_outliers(unlist_llama_pwu)
##### bard generation ######
bard_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-bard-formated.json"))
bard_df <- as.data.frame(bard_data)
unlist_bard_pwu <- unlist(bard_df$power.usage, use.names=FALSE)
filtered_bard_pwu <- remove_outliers(unlist_bard_pwu)
##### Kruskal-Wallis test ######
data_list <- list(filtered_bard_pwu, filtered_llama_pwu, filtered_chatgpt_pwu)
kruskal_result <- kruskal.test(data_list)
#print(kruskal_result$p.value)
#if (kruskal_result$p.value < 0.05) {  # Adjust the significance level as needed
#posthoc_result <- dunn.test(data_list, method = "bonferroni")
# Extract and print significant comparisons
#significant_comparisons <- posthoc_result$Comparison[posthoc_result$P.adjusted < 0.05]
#for (comparison in significant_comparisons) {
#cat(paste(comparison, "is significantly different.\n"))
#}
# You can choose other methods as well
#print(posthoc_result)
#}else
#print(paste(m,"-",t, "is not significant different"))
# Print the results
print(paste(m,"-",t))
print(kruskal_result)
#print(posthoc_result)
rm(chatgpt_data,chatgpt_df,unlist_chatgpt_pwu,filtered_chatgpt_pwu)
rm(llama_data,llama_df,unlist_llama_pwu,filtered_llama_pwu)
rm(bard_data,bard_df,unlist_bard_pwu,filtered_bard_pwu)
rm(data_list,kruskal_result)
}
}
source("~/VU/Master/GL/Green-Code-Guardians/Power-KW-test.R", echo=TRUE)
source("~/VU/Master/GL/Green-Code-Guardians/Power-KW-test.R", echo=TRUE)
source("~/VU/Master/GL/Green-Code-Guardians/Power-KW-test.R", echo=TRUE)
for (m in machines) {
for (t in tasks) {
##### chatgpt generation ######
chatgpt_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-chatgpt-formated.json"))
chatgpt_df <- as.data.frame(chatgpt_data)
unlist_chatgpt_pwu <- unlist(chatgpt_df$power.usage, use.names=FALSE)
filtered_chatgpt_pwu <- remove_outliers(unlist_chatgpt_pwu)
##### llama generation ######
llama_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-llama-formated.json"))
llama_df <- as.data.frame(llama_data)
unlist_llama_pwu <- unlist(llama_df$power.usage, use.names=FALSE)
filtered_llama_pwu <- remove_outliers(unlist_llama_pwu)
##### bard generation ######
bard_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-bard-formated.json"))
bard_df <- as.data.frame(bard_data)
unlist_bard_pwu <- unlist(bard_df$power.usage, use.names=FALSE)
filtered_bard_pwu <- remove_outliers(unlist_bard_pwu)
##### Kruskal-Wallis test ######
data_list <- list(filtered_bard_pwu, filtered_llama_pwu, filtered_chatgpt_pwu)
kruskal_result <- kruskal.test(data_list)
#print(kruskal_result$p.value)
#if (kruskal_result$p.value < 0.05) {  # Adjust the significance level as needed
#posthoc_result <- dunn.test(data_list, method = "bonferroni")
# Extract and print significant comparisons
#significant_comparisons <- posthoc_result$Comparison[posthoc_result$P.adjusted < 0.05]
#for (comparison in significant_comparisons) {
#cat(paste(comparison, "is significantly different.\n"))
#}
# You can choose other methods as well
#print(posthoc_result)
#}else
#print(paste(m,"-",t, "is not significant different"))
# Print the results
# print(paste(m,"-",t))
# print(kruskal_result)
#print(posthoc_result)
for (i in 1:length(data_list)) {
# Create a plot for each time series
plot(data_list[[i]], type = "l", main = names(data_list)[i])
}
nanowatt = 1000000000
print(sum(filtered_bard_pwu) / nanowatt)
print(sum(filtered_llama_pwu) / nanowatt)
print(sum(filtered_chatgpt_pwu) / nanowatt)
rm(chatgpt_data,chatgpt_df,unlist_chatgpt_pwu,filtered_chatgpt_pwu)
rm(llama_data,llama_df,unlist_llama_pwu,filtered_llama_pwu)
rm(bard_data,bard_df,unlist_bard_pwu,filtered_bard_pwu)
rm(data_list,kruskal_result)
}
}
for (m in machines) {
for (t in tasks) {
##### chatgpt generation ######
chatgpt_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-chatgpt-formated.json"))
chatgpt_df <- as.data.frame(chatgpt_data)
unlist_chatgpt_pwu <- unlist(chatgpt_df$power.usage, use.names=FALSE)
filtered_chatgpt_pwu <- remove_outliers(unlist_chatgpt_pwu)
##### llama generation ######
llama_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-llama-formated.json"))
llama_df <- as.data.frame(llama_data)
unlist_llama_pwu <- unlist(llama_df$power.usage, use.names=FALSE)
filtered_llama_pwu <- remove_outliers(unlist_llama_pwu)
##### bard generation ######
bard_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-bard-formated.json"))
bard_df <- as.data.frame(bard_data)
unlist_bard_pwu <- unlist(bard_df$power.usage, use.names=FALSE)
filtered_bard_pwu <- remove_outliers(unlist_bard_pwu)
##### Kruskal-Wallis test ######
data_list <- list(filtered_bard_pwu, filtered_llama_pwu, filtered_chatgpt_pwu)
kruskal_result <- kruskal.test(data_list)
#print(kruskal_result$p.value)
#if (kruskal_result$p.value < 0.05) {  # Adjust the significance level as needed
#posthoc_result <- dunn.test(data_list, method = "bonferroni")
# Extract and print significant comparisons
#significant_comparisons <- posthoc_result$Comparison[posthoc_result$P.adjusted < 0.05]
#for (comparison in significant_comparisons) {
#cat(paste(comparison, "is significantly different.\n"))
#}
# You can choose other methods as well
#print(posthoc_result)
#}else
#print(paste(m,"-",t, "is not significant different"))
# Print the results
# print(paste(m,"-",t))
# print(kruskal_result)
#print(posthoc_result)
line_colors <- c("red", "blue", "green")
for (i in 1:length(data_list)) {
# Create a plot for each time series
plot(data_list[[i]], type = "l", main = names(data_list)[i], col = line_colors[i])
}
legend("topright", legend = names(data_list), fill = line_colors)
nanowatt = 1000000000
print(sum(filtered_bard_pwu) / nanowatt)
print(sum(filtered_llama_pwu) / nanowatt)
print(sum(filtered_chatgpt_pwu) / nanowatt)
rm(chatgpt_data,chatgpt_df,unlist_chatgpt_pwu,filtered_chatgpt_pwu)
rm(llama_data,llama_df,unlist_llama_pwu,filtered_llama_pwu)
rm(bard_data,bard_df,unlist_bard_pwu,filtered_bard_pwu)
rm(data_list,kruskal_result)
}
}
for (m in machines) {
for (t in tasks) {
##### chatgpt generation ######
chatgpt_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-chatgpt-formated.json"))
chatgpt_df <- as.data.frame(chatgpt_data)
unlist_chatgpt_pwu <- unlist(chatgpt_df$power.usage, use.names=FALSE)
filtered_chatgpt_pwu <- remove_outliers(unlist_chatgpt_pwu)
##### llama generation ######
llama_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-llama-formated.json"))
llama_df <- as.data.frame(llama_data)
unlist_llama_pwu <- unlist(llama_df$power.usage, use.names=FALSE)
filtered_llama_pwu <- remove_outliers(unlist_llama_pwu)
##### bard generation ######
bard_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-bard-formated.json"))
bard_df <- as.data.frame(bard_data)
unlist_bard_pwu <- unlist(bard_df$power.usage, use.names=FALSE)
filtered_bard_pwu <- remove_outliers(unlist_bard_pwu)
##### Kruskal-Wallis test ######
data_list <- list(filtered_bard_pwu, filtered_llama_pwu, filtered_chatgpt_pwu)
kruskal_result <- kruskal.test(data_list)
#print(kruskal_result$p.value)
#if (kruskal_result$p.value < 0.05) {  # Adjust the significance level as needed
#posthoc_result <- dunn.test(data_list, method = "bonferroni")
# Extract and print significant comparisons
#significant_comparisons <- posthoc_result$Comparison[posthoc_result$P.adjusted < 0.05]
#for (comparison in significant_comparisons) {
#cat(paste(comparison, "is significantly different.\n"))
#}
# You can choose other methods as well
#print(posthoc_result)
#}else
#print(paste(m,"-",t, "is not significant different"))
# Print the results
# print(paste(m,"-",t))
# print(kruskal_result)
#print(posthoc_result)
plot(data_list[[1]], type = "n", main = "energy Comparison", xlab = "Time", ylab = "Value")
line_colors <- c("red", "blue", "green")
for (i in 1:length(data_list)) {
# Create a plot for each time series
plot(data_list[[i]], type = "l", main = names(data_list)[i], col = line_colors[i])
legend("topright", legend = names(data_list), fill = line_colors)
}
nanowatt = 1000000000
print(sum(filtered_bard_pwu) / nanowatt)
print(sum(filtered_llama_pwu) / nanowatt)
print(sum(filtered_chatgpt_pwu) / nanowatt)
rm(chatgpt_data,chatgpt_df,unlist_chatgpt_pwu,filtered_chatgpt_pwu)
rm(llama_data,llama_df,unlist_llama_pwu,filtered_llama_pwu)
rm(bard_data,bard_df,unlist_bard_pwu,filtered_bard_pwu)
rm(data_list,kruskal_result)
}
}
for (m in machines) {
for (t in tasks) {
##### chatgpt generation ######
chatgpt_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-chatgpt-formated.json"))
chatgpt_df <- as.data.frame(chatgpt_data)
unlist_chatgpt_pwu <- unlist(chatgpt_df$power.usage, use.names=FALSE)
filtered_chatgpt_pwu <- remove_outliers(unlist_chatgpt_pwu)
##### llama generation ######
llama_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-llama-formated.json"))
llama_df <- as.data.frame(llama_data)
unlist_llama_pwu <- unlist(llama_df$power.usage, use.names=FALSE)
filtered_llama_pwu <- remove_outliers(unlist_llama_pwu)
##### bard generation ######
bard_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-bard-formated.json"))
bard_df <- as.data.frame(bard_data)
unlist_bard_pwu <- unlist(bard_df$power.usage, use.names=FALSE)
filtered_bard_pwu <- remove_outliers(unlist_bard_pwu)
##### Kruskal-Wallis test ######
data_list <- list(filtered_bard_pwu, filtered_llama_pwu, filtered_chatgpt_pwu)
kruskal_result <- kruskal.test(data_list)
#print(kruskal_result$p.value)
#if (kruskal_result$p.value < 0.05) {  # Adjust the significance level as needed
#posthoc_result <- dunn.test(data_list, method = "bonferroni")
# Extract and print significant comparisons
#significant_comparisons <- posthoc_result$Comparison[posthoc_result$P.adjusted < 0.05]
#for (comparison in significant_comparisons) {
#cat(paste(comparison, "is significantly different.\n"))
#}
# You can choose other methods as well
#print(posthoc_result)
#}else
#print(paste(m,"-",t, "is not significant different"))
# Print the results
# print(paste(m,"-",t))
# print(kruskal_result)
#print(posthoc_result)
plot(data_list[[1]], type = "n", main = "energy Comparison", xlab = "Time", ylab = "Value")
line_colors <- c("red", "blue", "green")
for (i in 1:length(data_list)) {
# Create a plot for each time series
plot(data_list[[i]], type = "l", main = names(data_list)[i], col = line_colors[i])
legend("topright", legend = names(data_list)[i], fill = line_colors[i])
}
nanowatt = 1000000000
print(sum(filtered_bard_pwu) / nanowatt)
print(sum(filtered_llama_pwu) / nanowatt)
print(sum(filtered_chatgpt_pwu) / nanowatt)
rm(chatgpt_data,chatgpt_df,unlist_chatgpt_pwu,filtered_chatgpt_pwu)
rm(llama_data,llama_df,unlist_llama_pwu,filtered_llama_pwu)
rm(bard_data,bard_df,unlist_bard_pwu,filtered_bard_pwu)
rm(data_list,kruskal_result)
}
}
for (m in machines) {
for (t in tasks) {
##### chatgpt generation ######
chatgpt_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-chatgpt-formated.json"))
chatgpt_df <- as.data.frame(chatgpt_data)
unlist_chatgpt_pwu <- unlist(chatgpt_df$power.usage, use.names=FALSE)
filtered_chatgpt_pwu <- remove_outliers(unlist_chatgpt_pwu)
##### llama generation ######
llama_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-llama-formated.json"))
llama_df <- as.data.frame(llama_data)
unlist_llama_pwu <- unlist(llama_df$power.usage, use.names=FALSE)
filtered_llama_pwu <- remove_outliers(unlist_llama_pwu)
##### bard generation ######
bard_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-bard-formated.json"))
bard_df <- as.data.frame(bard_data)
unlist_bard_pwu <- unlist(bard_df$power.usage, use.names=FALSE)
filtered_bard_pwu <- remove_outliers(unlist_bard_pwu)
##### Kruskal-Wallis test ######
data_list <- list(filtered_bard_pwu, filtered_llama_pwu, filtered_chatgpt_pwu)
kruskal_result <- kruskal.test(data_list)
#print(kruskal_result$p.value)
#if (kruskal_result$p.value < 0.05) {  # Adjust the significance level as needed
#posthoc_result <- dunn.test(data_list, method = "bonferroni")
# Extract and print significant comparisons
#significant_comparisons <- posthoc_result$Comparison[posthoc_result$P.adjusted < 0.05]
#for (comparison in significant_comparisons) {
#cat(paste(comparison, "is significantly different.\n"))
#}
# You can choose other methods as well
#print(posthoc_result)
#}else
#print(paste(m,"-",t, "is not significant different"))
# Print the results
# print(paste(m,"-",t))
# print(kruskal_result)
#print(posthoc_result)
plot(data_list[[1]], type = "n", main = "energy Comparison", xlab = "Time", ylab = "Value")
line_colors <- c("red", "blue", "green")
for (i in 1:length(data_list)) {
# Create a plot for each time series
plot(data_list[[i]], type = "l", main = names(data_list)[i], col = line_colors[i])
}
legend("topright", legend = names(time_series_list), col = line_colors)
nanowatt = 1000000000
print(sum(filtered_bard_pwu) / nanowatt)
print(sum(filtered_llama_pwu) / nanowatt)
print(sum(filtered_chatgpt_pwu) / nanowatt)
rm(chatgpt_data,chatgpt_df,unlist_chatgpt_pwu,filtered_chatgpt_pwu)
rm(llama_data,llama_df,unlist_llama_pwu,filtered_llama_pwu)
rm(bard_data,bard_df,unlist_bard_pwu,filtered_bard_pwu)
rm(data_list,kruskal_result)
}
}
for (m in machines) {
for (t in tasks) {
##### chatgpt generation ######
chatgpt_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-chatgpt-formated.json"))
chatgpt_df <- as.data.frame(chatgpt_data)
unlist_chatgpt_pwu <- unlist(chatgpt_df$power.usage, use.names=FALSE)
filtered_chatgpt_pwu <- remove_outliers(unlist_chatgpt_pwu)
##### llama generation ######
llama_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-llama-formated.json"))
llama_df <- as.data.frame(llama_data)
unlist_llama_pwu <- unlist(llama_df$power.usage, use.names=FALSE)
filtered_llama_pwu <- remove_outliers(unlist_llama_pwu)
##### bard generation ######
bard_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-bard-formated.json"))
bard_df <- as.data.frame(bard_data)
unlist_bard_pwu <- unlist(bard_df$power.usage, use.names=FALSE)
filtered_bard_pwu <- remove_outliers(unlist_bard_pwu)
##### Kruskal-Wallis test ######
data_list <- list(filtered_bard_pwu, filtered_llama_pwu, filtered_chatgpt_pwu)
kruskal_result <- kruskal.test(data_list)
#print(kruskal_result$p.value)
#if (kruskal_result$p.value < 0.05) {  # Adjust the significance level as needed
#posthoc_result <- dunn.test(data_list, method = "bonferroni")
# Extract and print significant comparisons
#significant_comparisons <- posthoc_result$Comparison[posthoc_result$P.adjusted < 0.05]
#for (comparison in significant_comparisons) {
#cat(paste(comparison, "is significantly different.\n"))
#}
# You can choose other methods as well
#print(posthoc_result)
#}else
#print(paste(m,"-",t, "is not significant different"))
# Print the results
# print(paste(m,"-",t))
# print(kruskal_result)
#print(posthoc_result)
plot(data_list[[1]], type = "n", main = "energy Comparison", xlab = "Time", ylab = "Value")
line_colors <- c("red", "blue", "green")
for (i in 1:length(data_list)) {
# Create a plot for each time series
plot(data_list[[i]], type = "l", main = names(data_list)[i], col = line_colors[i])
}
legend("topright", legend = names(data_list), col = line_colors)
nanowatt = 1000000000
print(sum(filtered_bard_pwu) / nanowatt)
print(sum(filtered_llama_pwu) / nanowatt)
print(sum(filtered_chatgpt_pwu) / nanowatt)
rm(chatgpt_data,chatgpt_df,unlist_chatgpt_pwu,filtered_chatgpt_pwu)
rm(llama_data,llama_df,unlist_llama_pwu,filtered_llama_pwu)
rm(bard_data,bard_df,unlist_bard_pwu,filtered_bard_pwu)
rm(data_list,kruskal_result)
}
}
for (m in machines) {
for (t in tasks) {
##### chatgpt generation ######
chatgpt_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-chatgpt-formated.json"))
chatgpt_df <- as.data.frame(chatgpt_data)
unlist_chatgpt_pwu <- unlist(chatgpt_df$power.usage, use.names=FALSE)
filtered_chatgpt_pwu <- remove_outliers(unlist_chatgpt_pwu)
##### llama generation ######
llama_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-llama-formated.json"))
llama_df <- as.data.frame(llama_data)
unlist_llama_pwu <- unlist(llama_df$power.usage, use.names=FALSE)
filtered_llama_pwu <- remove_outliers(unlist_llama_pwu)
##### bard generation ######
bard_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-bard-formated.json"))
bard_df <- as.data.frame(bard_data)
unlist_bard_pwu <- unlist(bard_df$power.usage, use.names=FALSE)
filtered_bard_pwu <- remove_outliers(unlist_bard_pwu)
##### Kruskal-Wallis test ######
data_list <- list(filtered_bard_pwu, filtered_llama_pwu, filtered_chatgpt_pwu)
kruskal_result <- kruskal.test(data_list)
#print(kruskal_result$p.value)
#if (kruskal_result$p.value < 0.05) {  # Adjust the significance level as needed
#posthoc_result <- dunn.test(data_list, method = "bonferroni")
# Extract and print significant comparisons
#significant_comparisons <- posthoc_result$Comparison[posthoc_result$P.adjusted < 0.05]
#for (comparison in significant_comparisons) {
#cat(paste(comparison, "is significantly different.\n"))
#}
# You can choose other methods as well
#print(posthoc_result)
#}else
#print(paste(m,"-",t, "is not significant different"))
# Print the results
# print(paste(m,"-",t))
# print(kruskal_result)
#print(posthoc_result)
# Create an empty plot to initialize the plot
plot(data_list[[1]], type = "n", main = "Time Series Comparison", xlab = "Time", ylab = "Value")
# Define a vector of colors for the lines
line_colors <- c("red", "blue", "green")
# Add each time series to the same plot with a different color
for (i in 1:length(data_list)) {
lines(data_list[[i]], col = line_colors[i])
}
# Add a legend to label the lines
legend("topright", legend = names(data_list), col = line_colors)
nanowatt = 1000000000
print(sum(filtered_bard_pwu) / nanowatt)
print(sum(filtered_llama_pwu) / nanowatt)
print(sum(filtered_chatgpt_pwu) / nanowatt)
rm(chatgpt_data,chatgpt_df,unlist_chatgpt_pwu,filtered_chatgpt_pwu)
rm(llama_data,llama_df,unlist_llama_pwu,filtered_llama_pwu)
rm(bard_data,bard_df,unlist_bard_pwu,filtered_bard_pwu)
rm(data_list,kruskal_result)
}
}
for (m in machines) {
for (t in tasks) {
##### chatgpt generation ######
chatgpt_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-chatgpt-formated.json"))
chatgpt_df <- as.data.frame(chatgpt_data)
unlist_chatgpt_pwu <- unlist(chatgpt_df$power.usage, use.names=FALSE)
filtered_chatgpt_pwu <- remove_outliers(unlist_chatgpt_pwu)
##### llama generation ######
llama_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-llama-formated.json"))
llama_df <- as.data.frame(llama_data)
unlist_llama_pwu <- unlist(llama_df$power.usage, use.names=FALSE)
filtered_llama_pwu <- remove_outliers(unlist_llama_pwu)
##### bard generation ######
bard_data <- fromJSON(paste0("data/formatted-data/json/",m,"/",m,"-",t,"-bard-formated.json"))
bard_df <- as.data.frame(bard_data)
unlist_bard_pwu <- unlist(bard_df$power.usage, use.names=FALSE)
filtered_bard_pwu <- remove_outliers(unlist_bard_pwu)
##### Kruskal-Wallis test ######
data_list <- list(filtered_bard_pwu, filtered_llama_pwu, filtered_chatgpt_pwu)
kruskal_result <- kruskal.test(data_list)
#print(kruskal_result$p.value)
#if (kruskal_result$p.value < 0.05) {  # Adjust the significance level as needed
#posthoc_result <- dunn.test(data_list, method = "bonferroni")
# Extract and print significant comparisons
#significant_comparisons <- posthoc_result$Comparison[posthoc_result$P.adjusted < 0.05]
#for (comparison in significant_comparisons) {
#cat(paste(comparison, "is significantly different.\n"))
#}
# You can choose other methods as well
#print(posthoc_result)
#}else
#print(paste(m,"-",t, "is not significant different"))
# Print the results
# print(paste(m,"-",t))
# print(kruskal_result)
#print(posthoc_result)
# Create an empty plot to initialize the plot
plot(data_list[[1]], type = "n", main = "Time Series Comparison", xlab = "Time", ylab = "Value")
# Define a vector of colors for the lines
line_colors <- c("red", "blue", "green")
# Add each time series to the same plot with a different color
for (i in 1:length(data_list)) {
lines(data_list[[i]], col = line_colors[i])
}
nanowatt = 1000000000
print(sum(filtered_bard_pwu) / nanowatt)
print(sum(filtered_llama_pwu) / nanowatt)
print(sum(filtered_chatgpt_pwu) / nanowatt)
rm(chatgpt_data,chatgpt_df,unlist_chatgpt_pwu,filtered_chatgpt_pwu)
rm(llama_data,llama_df,unlist_llama_pwu,filtered_llama_pwu)
rm(bard_data,bard_df,unlist_bard_pwu,filtered_bard_pwu)
rm(data_list,kruskal_result)
}
}
clear
source("~/VU/Master/GL/Green-Code-Guardians/Power-KW-test.R", echo=TRUE)
# Print the results
print(paste(m,"-",t))
source("~/VU/Master/GL/Green-Code-Guardians/Power-KW-test.R", echo=TRUE)
source("~/VU/Master/GL/Green-Code-Guardians/Power-KW-test.R", echo=TRUE)
source("~/VU/Master/GL/Green-Code-Guardians/Power-KW-test.R", echo=TRUE)
source("~/VU/Master/GL/Green-Code-Guardians/Power-KW-test.R", echo=TRUE)
source("~/VU/Master/GL/Green-Code-Guardians/Power-KW-test.R", echo=TRUE)
chatgpt_watt = round(sum(filtered_chatgpt_pwu) / nanowatt,1)
source("~/VU/Master/GL/Green-Code-Guardians/Power-KW-test.R", echo=TRUE)
nanowatt = 1000000000
source("~/VU/Master/GL/Green-Code-Guardians/Power-usage-Watts.R", echo=TRUE)
source("~/VU/Master/GL/Green-Code-Guardians/Power-usage-Watts.R", echo=TRUE)
source("~/VU/Master/GL/Green-Code-Guardians/Power-KW-test.R", echo=TRUE)
for (t in tasks) {
print(paste(m,"-",t))
for (l in llms) {
fname = paste0(m,'-',t,'-',l,'-formated')
json_path = paste0('data/formatted-data/json/',m,'/',fname,'.json')
task_data <- fromJSON(json_path)
task_df <- as.data.frame(task_data)
task_pwu = watt = round(sum(task_df$power.usage) / nanowatt,1)
print(paste(l,':', task_pwu,'Watt'))
rm(task_data)
rm(task_df)
}
}
for (t in tasks) {
print(paste(m,"-",t))
for (l in llms) {
fname = paste0(m,'-',t,'-',l,'-formated')
json_path = paste0('data/formatted-data/json/',m,'/',fname,'.json')
task_data <- fromJSON(json_path)
task_df <- as.data.frame(task_data)
task_pwu = watt = round(sum(task_df$power.usage) / nanowatt,1)
print(paste(l,':', task_pwu,'Watt'))
rm(task_data)
rm(task_df)
}
}
source("~/VU/Master/GL/Green-Code-Guardians/Power-usage-Watts.R", echo=TRUE)
source("~/VU/Master/GL/Green-Code-Guardians/Power-usage-Watts.R", echo=TRUE)
source("~/VU/Master/GL/Green-Code-Guardians/Normality.R", echo=TRUE)
source("~/VU/Master/GL/Green-Code-Guardians/Normality.R", echo=TRUE)
